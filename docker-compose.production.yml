version: '3.8'

# Production Docker Compose Configuration
# For deployment to Google Cloud Run or other production environments
# This file focuses on Cloud Run-compatible services

services:
  # Backend API Service
  backend:
    build:
      context: .
      dockerfile: docker/Dockerfile.backend.prod
    ports:
      - "${PORT:-8080}:${PORT:-8080}"
    env_file:
      - .env.production
    environment:
      - ENVIRONMENT=production
      - PORT=${PORT:-8080}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - USE_SECRET_MANAGER=true
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/gcp-credentials.json
    volumes:
      - ./gcp-credentials.json:/app/gcp-credentials.json:ro
      - prod_models:/app/models
      - prod_temp:/tmp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${PORT:-8080}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
        reservations:
          memory: 4G
          cpus: '2'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Celery Workers for Training (GPU-enabled)
  celery-training:
    build:
      context: .
      dockerfile: docker/Dockerfile.celery.prod
    command: celery -A src.celery_app worker --loglevel=info --queue=training --concurrency=2 --max-tasks-per-child=10
    env_file:
      - .env.production
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - USE_SECRET_MANAGER=true
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/gcp-credentials.json
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    volumes:
      - ./gcp-credentials.json:/app/gcp-credentials.json:ro
      - prod_models:/app/models
      - prod_datasets:/app/datasets
      - prod_temp:/tmp
    healthcheck:
      test: ["CMD", "celery", "-A", "src.celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: '8'
        reservations:
          memory: 8G
          cpus: '4'
    runtime: nvidia  # For GPU support
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Celery Workers for Inference
  celery-inference:
    build:
      context: .
      dockerfile: docker/Dockerfile.celery.prod
    command: celery -A src.celery_app worker --loglevel=info --queue=inference --concurrency=4 --max-tasks-per-child=50
    env_file:
      - .env.production
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - USE_SECRET_MANAGER=true
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/gcp-credentials.json
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    volumes:
      - ./gcp-credentials.json:/app/gcp-credentials.json:ro
      - prod_models:/app/models
      - prod_images:/app/images
      - prod_temp:/tmp
    healthcheck:
      test: ["CMD", "celery", "-A", "src.celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: '6'
        reservations:
          memory: 6G
          cpus: '3'
    runtime: nvidia  # For GPU support
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Celery Workers for Evaluation
  celery-evaluation:
    build:
      context: .
      dockerfile: docker/Dockerfile.celery.prod
    command: celery -A src.celery_app worker --loglevel=info --queue=evaluation --concurrency=2 --max-tasks-per-child=20
    env_file:
      - .env.production
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - USE_SECRET_MANAGER=true
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/gcp-credentials.json
    volumes:
      - ./gcp-credentials.json:/app/gcp-credentials.json:ro
      - prod_models:/app/models
      - prod_datasets:/app/datasets
      - prod_temp:/tmp
    healthcheck:
      test: ["CMD", "celery", "-A", "src.celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
        reservations:
          memory: 4G
          cpus: '2'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Celery Workers for Deployment
  celery-deployment:
    build:
      context: .
      dockerfile: docker/Dockerfile.celery.prod
    command: celery -A src.celery_app worker --loglevel=info --queue=deployment --concurrency=1 --max-tasks-per-child=10
    env_file:
      - .env.production
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - USE_SECRET_MANAGER=true
      - GCP_PROJECT_ID=${GCP_PROJECT_ID}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/gcp-credentials.json
    volumes:
      - ./gcp-credentials.json:/app/gcp-credentials.json:ro
      - prod_models:/app/models
      - prod_temp:/tmp
    healthcheck:
      test: ["CMD", "celery", "-A", "src.celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 20s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Frontend (Next.js) - Production Build
  frontend:
    build:
      context: .
      dockerfile: docker/Dockerfile.frontend.prod
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    env_file:
      - .env.production
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=${BACKEND_URL}
      - NEXT_PUBLIC_WS_URL=${BACKEND_URL}
      - NEXT_PUBLIC_APP_NAME="ML Evaluation Platform"
      - NEXT_PUBLIC_APP_VERSION=1.0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
          cpus: '0.5'
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Nginx Reverse Proxy (Optional for multi-service deployments)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - backend
      - frontend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

volumes:
  prod_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/ml-eval/models
  
  prod_images:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/ml-eval/images
  
  prod_datasets:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/ml-eval/datasets
  
  prod_temp:
    driver: local
    driver_opts:
      type: tmpfs
      device: tmpfs
      o: size=2g,uid=1000,gid=1000
  
  nginx_logs:
    driver: local

networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# Production-specific overrides
x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "100m"
    max-file: "5"

x-restart: &default-restart
  restart_policy:
    condition: on-failure
    delay: 5s
    max_attempts: 3
    window: 120s